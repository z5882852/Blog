<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>网络数据采集 | 怪诞不经</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="网络数据采集大多数使用爬虫实现，爬虫是一种自动化获取互联网信息的程序，它可以模拟人的行为，访问网页、提取数据并进行处理分析。使用 Python 编程语言编写爬虫程序非常方便和灵活，因为它具有简洁的语法和丰富的第三方库。 基本原理Python 爬虫的基本原理包括以下几个步骤：  发起 HTTP 请求：使用Python的网络库（如requests）发起 HTTP 请求，向目标网页发送请求并获取响应。">
<meta property="og:type" content="article">
<meta property="og:title" content="网络数据采集">
<meta property="og:url" content="http://z5882852.github.io/Blog/Big-Data-Competition/Network-Data-Collection/index/index.html">
<meta property="og:site_name" content="怪诞不经">
<meta property="og:description" content="网络数据采集大多数使用爬虫实现，爬虫是一种自动化获取互联网信息的程序，它可以模拟人的行为，访问网页、提取数据并进行处理分析。使用 Python 编程语言编写爬虫程序非常方便和灵活，因为它具有简洁的语法和丰富的第三方库。 基本原理Python 爬虫的基本原理包括以下几个步骤：  发起 HTTP 请求：使用Python的网络库（如requests）发起 HTTP 请求，向目标网页发送请求并获取响应。">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2023-06-06T12:39:00.000Z">
<meta property="article:modified_time" content="2023-07-16T18:42:59.709Z">
<meta property="article:author" content="z5882852">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="爬虫">
<meta property="article:tag" content="数据采集">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/Blog/atom.xml" title="怪诞不经" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/Blog/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/Blog/css/style.css">

  
    
<link rel="stylesheet" href="/Blog/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/Blog/" id="logo">怪诞不经</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/Blog/">Home</a>
        
          <a class="main-nav-link" href="/Blog/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/Blog/atom.xml" title="RSS 订阅"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="搜索"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="搜索"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://z5882852.github.io/Blog"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-Big-Data-Competition/Network-Data-Collection/index" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/Blog/Big-Data-Competition/Network-Data-Collection/index/" class="article-date">
  <time class="dt-published" datetime="2023-06-06T12:39:00.000Z" itemprop="datePublished">2023-06-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      网络数据采集
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>网络数据采集大多数使用爬虫实现，爬虫是一种自动化获取互联网信息的程序，它可以模拟人的行为，访问网页、提取数据并进行处理分析。使用 Python 编程语言编写爬虫程序非常方便和灵活，因为它具有简洁的语法和丰富的第三方库。</p>
<h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><p>Python 爬虫的基本原理包括以下几个步骤：</p>
<ol>
<li><p>发起 HTTP 请求：使用<code>Python</code>的网络库（如<code>requests</code>）发起 HTTP 请求，向目标网页发送请求并获取响应。</p>
</li>
<li><p>解析网页内容：使用<code>HTML</code>解析库（如<code>BeautifulSoup</code>）解析网页的<code>HTML</code>内容，提取出需要的数据。</p>
</li>
<li><p>数据处理和存储：对提取的数据进行处理和清洗，可以使用<code>Python</code>的数据处理库（如<code>pandas</code>）进行数据分析和处理。将数据存储到文件、数据库或其他数据存储介质中。</p>
</li>
<li><p>可选步骤：爬虫还可以进行更高级的操作，例如处理<code>JavaScript</code>动态渲染的网页、使用代理、处理验证码等。</p>
</li>
</ol>
<h2 id="Python-爬虫的常用库"><a href="#Python-爬虫的常用库" class="headerlink" title="Python 爬虫的常用库"></a>Python 爬虫的常用库</h2><p>以下是一些在<code>Python</code>爬虫中常用的库：</p>
<ul>
<li><strong>requests：</strong> 用于发送 HTTP 请求和处理响应。</li>
<li><strong>BeautifulSoup：</strong> 用于解析 HTML 和 XML 文件，提取需要的数据。</li>
<li><strong>Scrapy：</strong> 一个功能强大的爬虫框架，提供了高度可定制的爬虫功能。</li>
<li><strong>Selenium：</strong> 用于处理 JavaScript 渲染的网页，模拟用户操作。</li>
<li><strong>pandas：</strong> 用于数据处理和分析。</li>
<li><strong>MongoDB：</strong> 一种流行的 NoSQL 数据库，常用于存储爬虫获取的数据。</li>
</ul>
<h2 id="示例代码"><a href="#示例代码" class="headerlink" title="示例代码"></a>示例代码</h2><p>以下是一个简单的使用<code>Python</code>和<code>requests</code>库编写的爬虫示例代码，用于获取网页内容：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发起 HTTP 请求</span></span><br><span class="line">response = requests.get(<span class="string">&#x27;http://example.com&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取网页内容</span></span><br><span class="line">content = response.text</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印网页内容</span></span><br><span class="line"><span class="built_in">print</span>(content)</span><br></pre></td></tr></table></figure>

<h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><h3 id="获取百度实时热点排行榜信息"><a href="#获取百度实时热点排行榜信息" class="headerlink" title="获取百度实时热点排行榜信息"></a>获取百度实时热点排行榜信息</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理字符串中的空白符，并拼接字符串</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">processing</span>(<span class="params">strs</span>):</span><br><span class="line">    s = <span class="string">&#x27;&#x27;</span>  <span class="comment"># 定义保存内容的字符串</span></span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> strs:</span><br><span class="line">        n = <span class="string">&#x27;&#x27;</span>.join(n.split(<span class="string">&quot; &quot;</span>))  <span class="comment"># 去除空白符</span></span><br><span class="line">        s = s + n  <span class="comment"># 拼接字符串</span></span><br><span class="line">    <span class="keyword">return</span> s  <span class="comment"># 返回拼接后的字符串</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义解析页面函数，用来获取百度实时热点排行榜信息</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_hotspot_info</span>(<span class="params">url, headers</span>):</span><br><span class="line">    response = requests.get(url=url, headers=headers)  <span class="comment"># 发送网络请求</span></span><br><span class="line">    html = etree.HTML(response.text)  <span class="comment"># 解析HTML字符串</span></span><br><span class="line">    div_all = html.xpath(<span class="string">&#x27;//div[@class=&quot;category-wrap_iQLoo horizontal_1eKyQ&quot;]&#x27;</span>)  <span class="comment"># 获取实时热点相关所有信息</span></span><br><span class="line">    <span class="keyword">for</span> div <span class="keyword">in</span> div_all:</span><br><span class="line">        rank = div.xpath(<span class="string">&#x27;.//div[contains(@class, &quot;index_1Ew5p&quot;)]&#x27;</span>)[<span class="number">0</span>].xpath(<span class="string">&quot;string(.)&quot;</span>) <span class="comment"># 获取实时热点排名</span></span><br><span class="line">        rank = processing(rank)  <span class="comment"># 处理实时热点排名</span></span><br><span class="line">        title = div.xpath(<span class="string">&#x27;.//div[@class=&quot;c-single-text-ellipsis&quot;]&#x27;</span>)[<span class="number">0</span>].xpath(<span class="string">&quot;string(.)&quot;</span>)  <span class="comment"># 获取实时热点标题</span></span><br><span class="line">        title = processing(title)  <span class="comment"># 处理实时热点标题</span></span><br><span class="line">        index = div.xpath(<span class="string">&#x27;.//div[@class=&quot;hot-index_1Bl1a&quot;]&#x27;</span>)[<span class="number">0</span>].xpath(<span class="string">&quot;string(.)&quot;</span>)  <span class="comment"># 获取实时热点热搜指数</span></span><br><span class="line">        index = processing(index)  <span class="comment"># 处理实时热点热搜指数</span></span><br><span class="line">        record = rank + <span class="string">&#x27;\t&#x27;</span> + title + <span class="string">&#x27;\t&#x27;</span> + index  <span class="comment"># 拼接百度实时热点排行榜信息</span></span><br><span class="line">        <span class="built_in">print</span>(record)  <span class="comment"># 输出</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 程序入口</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    url = <span class="string">&#x27;https://top.baidu.com/board?tab=realtime&#x27;</span>  <span class="comment"># 百度实时热点排行榜链接</span></span><br><span class="line">    h = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span> : <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36 Edg/113.0.1774.57&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    get_hotspot_info(url, h) <span class="comment"># 调用爬虫方法，获取百度实时热点排行榜信息</span></span><br></pre></td></tr></table></figure>

<h3 id="获取网易新闻热点排行Top10信息"><a href="#获取网易新闻热点排行Top10信息" class="headerlink" title="获取网易新闻热点排行Top10信息"></a>获取网易新闻热点排行Top10信息</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义解析页面函数，用来获取网易新闻热点排行Top10信息</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_news_info</span>(<span class="params">url, headers</span>):</span><br><span class="line">    response = requests.get(url=url, headers=headers)  <span class="comment"># 发送网络请求</span></span><br><span class="line">    soup = BeautifulSoup(response.text, <span class="string">&quot;lxml&quot;</span>)  <span class="comment"># 创建一个BeautifulSoup对象，获取页面正文</span></span><br><span class="line">    all_news = soup.find(<span class="string">&#x27;div&#x27;</span>, class_=<span class="string">&quot;mod_hot_rank&quot;</span>).find(<span class="string">&#x27;ul&#x27;</span>).find_all(<span class="string">&#x27;li&#x27;</span>)  <span class="comment"># 获取网易新闻热点排行Top10内容</span></span><br><span class="line">    news_list = []  <span class="comment"># 创建空列表</span></span><br><span class="line">    <span class="keyword">for</span> news <span class="keyword">in</span> all_news:</span><br><span class="line">        news_rank = news.em.string  <span class="comment"># 获取新闻排名</span></span><br><span class="line">        news_title = news.a.string  <span class="comment"># 获取新闻标题</span></span><br><span class="line">        posts_num = news.span.string  <span class="comment"># 获取新闻跟帖数</span></span><br><span class="line">        news_url = news.a.get(<span class="string">&#x27;href&#x27;</span>)  <span class="comment"># 获取新闻链接</span></span><br><span class="line">        news_list.append([news_rank, news_title, posts_num, news_url])  <span class="comment"># 把每条新闻的排名、标题、跟帖数和链接添加到一个列表中，再追加到一个大列表中</span></span><br><span class="line">    <span class="keyword">return</span> news_list  <span class="comment"># 返回列表</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 程序入口</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    url = <span class="string">&#x27;https://news.163.com/&#x27;</span>  <span class="comment"># 网易新闻首页链接</span></span><br><span class="line">    <span class="comment"># 定义请求头信息</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/71.0.3578.80 Chrome/71.0.3578.80 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">    news_list = get_news_info(url, headers)  <span class="comment"># 调用爬虫方法，获取网易新闻热点排行Top10</span></span><br><span class="line">    <span class="built_in">print</span>(news_list)  <span class="comment"># 输出网易新闻热点排行Top10信息</span></span><br></pre></td></tr></table></figure>

<h3 id="获取百度贴吧中”police”贴吧帖子标题、作者、链接和创建时间"><a href="#获取百度贴吧中”police”贴吧帖子标题、作者、链接和创建时间" class="headerlink" title="获取百度贴吧中”police”贴吧帖子标题、作者、链接和创建时间"></a>获取百度贴吧中”police”贴吧帖子标题、作者、链接和创建时间</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请求页面的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_page</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="comment"># 定义请求头信息</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/71.0.3578.80 Chrome/71.0.3578.80 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = requests.get(url=url, headers=headers)  <span class="comment"># 发送网络请求</span></span><br><span class="line">        <span class="keyword">if</span> response.status_code == <span class="number">200</span>:  <span class="comment"># 判断请求是否成功</span></span><br><span class="line">            <span class="keyword">return</span> response.text  <span class="comment"># 以文本形式返回整个HTML页面</span></span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;请求页面错误！！！&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义解析贴吧网页的爬虫函数，用来获取&quot;police吧&quot;帖子标题、作者、链接和创建时间</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_posts_info</span>(<span class="params">html</span>):</span><br><span class="line">    posts_title = re.findall(<span class="string">r&#x27;class=&quot;j_th_tit &quot;&gt;(.+?)&lt;/a&gt;&#x27;</span>, html)   <span class="comment"># 帖子标题</span></span><br><span class="line">    posts_author = re.findall(<span class="string">r&#x27;title=&quot;主题作者:(.+?)&quot;&#x27;</span>, html)  <span class="comment"># 帖子作者</span></span><br><span class="line">    posts_href = re.findall(<span class="string">r&#x27;href=&quot;/p/(.+?)&quot;&#x27;</span>, html)  <span class="comment"># 帖子链接</span></span><br><span class="line">    post_createtime = re.findall(<span class="string">r&#x27;title=&quot;创建时间&quot;&gt;(.+?)&lt;&#x27;</span>, html)  <span class="comment"># 帖子创建时间</span></span><br><span class="line">    <span class="comment">#print(&#x27;帖子标题：&#x27;, posts_title)</span></span><br><span class="line">    <span class="comment">#print(&#x27;帖子作者：&#x27;, posts_author)</span></span><br><span class="line">    <span class="comment">#print(&#x27;帖子链接：&#x27;, posts_href)</span></span><br><span class="line">    <span class="comment">#print(&#x27;帖子创建时间：&#x27;, post_createtime)</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">list</span>(<span class="built_in">zip</span>(posts_title, posts_author, posts_href, post_createtime))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_as_txt</span>(<span class="params">text</span>):   </span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;posts.txt&quot;</span>,<span class="string">&quot;a&quot;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(text + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 程序入口</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    base_url = <span class="string">&#x27;https://tieba.baidu.com/f?kw=police&amp;ie=utf-8&amp;pn=&#123;page&#125;&#x27;</span>  <span class="comment"># &quot;police吧&quot;基础URL地址</span></span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">201</span>, <span class="number">50</span>):  <span class="comment"># 每页间隔50，实现循环，共5页</span></span><br><span class="line">        page_url = base_url.<span class="built_in">format</span>(page = i)  <span class="comment"># 通过format替换切换页码的URL地址</span></span><br><span class="line">        html = get_page(page_url)  <span class="comment"># 调用请求页面的函数，获取整个HTML页面</span></span><br><span class="line">        posts_data = get_posts_info(html)  <span class="comment"># 调用解析贴吧网页的爬虫函数，获取&quot;police&quot;贴吧帖子标题、作者、链接和创建时间</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> posts_data:</span><br><span class="line">            title = data[<span class="number">0</span>]</span><br><span class="line">            author = data[<span class="number">1</span>]</span><br><span class="line">            href = <span class="string">&#x27;https://tieba.baidu.com/p/&#x27;</span> + data[<span class="number">2</span>]</span><br><span class="line">            time = data[<span class="number">3</span>]</span><br><span class="line">            text = title + <span class="string">&#x27;\t&#x27;</span> + author + <span class="string">&#x27;\t&#x27;</span> + href + <span class="string">&#x27;\t&#x27;</span> + time</span><br><span class="line">            save_as_txt(text)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;已写入数据：&quot;</span>,i)</span><br><span class="line">            i += <span class="number">1</span></span><br></pre></td></tr></table></figure>

<h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><h4 id="俗话说爬虫写得好，牢饭吃到饱。使用爬虫必须遵循以下几点"><a href="#俗话说爬虫写得好，牢饭吃到饱。使用爬虫必须遵循以下几点" class="headerlink" title="俗话说爬虫写得好，牢饭吃到饱。使用爬虫必须遵循以下几点:"></a>俗话说爬虫写得好，牢饭吃到饱。使用爬虫必须遵循以下几点:</h4><ul>
<li><h5 id="不要爬敏感数据、隐私数据、非公开数据。"><a href="#不要爬敏感数据、隐私数据、非公开数据。" class="headerlink" title="不要爬敏感数据、隐私数据、非公开数据。"></a>不要爬敏感数据、隐私数据、非公开数据。</h5></li>
<li><h5 id="不要干扰被爬取网站或系统的正常运营。"><a href="#不要干扰被爬取网站或系统的正常运营。" class="headerlink" title="不要干扰被爬取网站或系统的正常运营。"></a>不要干扰被爬取网站或系统的正常运营。</h5></li>
<li><h5 id="不要规避网站经营者设置的反爬虫措施或者破解服务器防抓取措施，非法获取相关信息。"><a href="#不要规避网站经营者设置的反爬虫措施或者破解服务器防抓取措施，非法获取相关信息。" class="headerlink" title="不要规避网站经营者设置的反爬虫措施或者破解服务器防抓取措施，非法获取相关信息。"></a>不要规避网站经营者设置的反爬虫措施或者破解服务器防抓取措施，非法获取相关信息。</h5></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://z5882852.github.io/Blog/Big-Data-Competition/Network-Data-Collection/index/" data-id="clko1a7kk0005i8fl4qwtgff5" data-title="网络数据采集" class="article-share-link"><span class="fa fa-share">分享</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/Blog/tags/Python/" rel="tag">Python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/Blog/tags/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/" rel="tag">数据采集</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/Blog/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/Blog/Big-Data-Competition/Hadoop-Data-Analysis/index/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">前一篇</strong>
      <div class="article-nav-title">
        
          Hadoop数据分析
        
      </div>
    </a>
  
  
    <a href="/Blog/Big-Data-Competition/Python-Data-Analysis/index/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">后一篇</strong>
      <div class="article-nav-title">Python数据分析</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/Blog/tags/Hadoop/" rel="tag">Hadoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/Blog/tags/Python/" rel="tag">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/Blog/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag">卷积神经网络</a></li><li class="tag-list-item"><a class="tag-list-link" href="/Blog/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据</a></li><li class="tag-list-item"><a class="tag-list-link" href="/Blog/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" rel="tag">数据分析</a></li><li class="tag-list-item"><a class="tag-list-link" href="/Blog/tags/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/" rel="tag">数据可视化</a></li><li class="tag-list-item"><a class="tag-list-link" href="/Blog/tags/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/" rel="tag">数据采集</a></li><li class="tag-list-item"><a class="tag-list-link" href="/Blog/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/Blog/tags/%E6%AF%94%E8%B5%9B/" rel="tag">比赛</a></li><li class="tag-list-item"><a class="tag-list-link" href="/Blog/tags/%E6%BA%90%E7%A0%81/" rel="tag">源码</a></li><li class="tag-list-item"><a class="tag-list-link" href="/Blog/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a></li><li class="tag-list-item"><a class="tag-list-link" href="/Blog/tags/%E9%A2%98%E7%9B%AE/" rel="tag">题目</a></li><li class="tag-list-item"><a class="tag-list-link" href="/Blog/tags/%E9%AA%8C%E8%AF%81%E7%A0%81/" rel="tag">验证码</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/Blog/tags/Hadoop/" style="font-size: 13.33px;">Hadoop</a> <a href="/Blog/tags/Python/" style="font-size: 20px;">Python</a> <a href="/Blog/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 10px;">卷积神经网络</a> <a href="/Blog/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" style="font-size: 10px;">大数据</a> <a href="/Blog/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" style="font-size: 13.33px;">数据分析</a> <a href="/Blog/tags/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/" style="font-size: 16.67px;">数据可视化</a> <a href="/Blog/tags/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/" style="font-size: 10px;">数据采集</a> <a href="/Blog/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">机器学习</a> <a href="/Blog/tags/%E6%AF%94%E8%B5%9B/" style="font-size: 10px;">比赛</a> <a href="/Blog/tags/%E6%BA%90%E7%A0%81/" style="font-size: 10px;">源码</a> <a href="/Blog/tags/%E7%88%AC%E8%99%AB/" style="font-size: 13.33px;">爬虫</a> <a href="/Blog/tags/%E9%A2%98%E7%9B%AE/" style="font-size: 10px;">题目</a> <a href="/Blog/tags/%E9%AA%8C%E8%AF%81%E7%A0%81/" style="font-size: 10px;">验证码</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/Blog/archives/2023/07/">七月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/Blog/archives/2023/06/">六月 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/Blog/Machine-Learning/Machine-Learning/">使用卷积神经网络模型来识别验证码</a>
          </li>
        
          <li>
            <a href="/Blog/Big-Data-Competition/Big-Data-Competition/">大数据比赛</a>
          </li>
        
          <li>
            <a href="/Blog/Big-Data-Competition/Hadoop-Data-Analysis/index/">Hadoop数据分析</a>
          </li>
        
          <li>
            <a href="/Blog/Big-Data-Competition/Network-Data-Collection/index/">网络数据采集</a>
          </li>
        
          <li>
            <a href="/Blog/Big-Data-Competition/Python-Data-Analysis/index/">Python数据分析</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2023 z5882852<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/Blog/" class="mobile-nav-link">Home</a>
  
    <a href="/Blog/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/Blog/js/jquery-3.6.4.min.js"></script>



  
<script src="/Blog/fancybox/jquery.fancybox.min.js"></script>




<script src="/Blog/js/script.js"></script>





  </div>
</body>
</html>